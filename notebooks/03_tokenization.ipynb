{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_checkpoint = \"Yukang/Llama-2-7b-longlora-32k-ft\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_checkpoint, device_map=\"auto\", low_cpu_mem_usage=True, torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.add_bos_token:\n",
    "    tokenizer.add_bos_token = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"w11wo/FourSquare-NYC-POI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11022/11022 [00:17<00:00, 620.79 examples/s]\n",
      "Map: 100%|██████████| 1429/1429 [00:02<00:00, 687.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: tokenizer(x[\"llama_prompt\"]), batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = \"\"\"<s>[INST] <<SYS>>\n",
    "You are user 902 and your basic information is as follows:\n",
    "Age: adult; Gender: female; Education: college & beyond; SocioEco: middle.\n",
    "You have the following traits: extroverted, agreeable, conscientious, emotionally stable, open.\n",
    "You have the following preferences: socializing, exploring new cafés, enjoying sweets, visiting bars, traveling via train.\n",
    "You have the following routines: frequent visits to cafés, shopping at department stores, regular trips to train stations, working in an office, indulging in treats from cupcake shops.\n",
    "User 902 is a sociable and friendly adult who enjoys exploring the urban environment around her. Frequently visiting cafés and cupcake shops showcases her love for social gatherings and sweet delights. She has a solid educational background, likely holding a college degree, which aligns with her conscientious nature in managing her life and work responsibilities from her regular visits to the office. User 902 exhibits openness with a flair for experiencing diverse flavors, seen in her trips to food trucks and bars. She is emotionally stable and likely has a close-knit group of friends with whom she enjoys outings, indicated by her frequent visits to lively spots. Train stations appear often in her check-ins suggesting she enjoys traveling and exploring different areas. Future potential places of interest may include new cafés, food markets, and cultural festivals in the city, reflecting her adventurous and social spirit.\n",
    "<</SYS>>\n",
    "\n",
    "The following data is a trajectory of user 902: At 2012-04-25 09:30:56, user 902 visited POI id 1090 which is a Cupcake Shop and has Category id 188. At 2012-04-25 13:58:55, user 902 visited POI id 950 which is a Food Truck and has Category id 202.\n",
    "Given the data, At 2012-04-25 21:24:11, Which POI id will user 902 visit? Note that POI id is an integer in the range from 0 to 4981. [/INST] At 2012-04-25 21:24:11, user 902 will visit POI id 2955. </s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tokens_with_ids(txt):\n",
    "    tokens = tokenizer.tokenize(txt, add_special_tokens=False)\n",
    "    token_ids = tokenizer.encode(txt, add_special_tokens=False)\n",
    "    print(list(zip(tokens, token_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁', 29871), ('4', 29946), ('9', 29929), ('8', 29947), ('1', 29896), ('.', 29889), ('▁[', 518), ('/', 29914), ('INST', 25580), (']', 29962), ('▁At', 2180)]\n"
     ]
    }
   ],
   "source": [
    "print_tokens_with_ids(\"4981. [/INST] At\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁[', 518), ('/', 29914), ('INST', 25580), (']', 29962)]\n"
     ]
    }
   ],
   "source": [
    "print_tokens_with_ids(\" [/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11022/11022 [00:07<00:00, 1401.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13904"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "max(len(dataset[\"train\"][i][\"input_ids\"]) for i in tqdm(range(len(dataset[\"train\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1429/1429 [00:00<00:00, 1651.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10532"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(dataset[\"test\"][i][\"input_ids\"]) for i in tqdm(range(len(dataset[\"test\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
