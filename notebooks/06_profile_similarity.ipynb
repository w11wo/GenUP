{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/tky/user_profile_1.json'),\n",
       " PosixPath('../data/tky/user_profile_2.json'),\n",
       " PosixPath('../data/tky/user_profile_3.json'),\n",
       " PosixPath('../data/tky/user_profile_4.json'),\n",
       " PosixPath('../data/tky/user_profile_5.json')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"../data\")\n",
    "dataset_name = \"tky\"\n",
    "dataset_path = path / dataset_name\n",
    "json_files = sorted(dataset_path.glob(\"user_profile_*.json\"), key=lambda x: int(x.stem.split(\"_\")[-1]))\n",
    "json_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "user_profiles = {}\n",
    "\n",
    "for json_file in json_files:\n",
    "    user_id = json_file.stem.split(\"_\")[-1]\n",
    "    with open(json_file, \"r\") as f:\n",
    "        user_profile = json.load(f)\n",
    "    \n",
    "    age, gender, education, socioeco = user_profile[\"attributes\"]\n",
    "    traits = \", \".join(user_profile[\"traits\"])\n",
    "    preferences = \", \".join(user_profile[\"preferences\"])\n",
    "    routines = \", \".join(user_profile[\"routines\"])\n",
    "    user_profile_str = user_profile[\"user_profile\"]\n",
    "\n",
    "    system_prompt = f\"\"\"You are user {user_id} and your basic information is as follows:\n",
    "Age: {age}; Gender: {gender}; Education: {education}; SocioEco: {socioeco}.\n",
    "You have the following traits: {traits}.\n",
    "You have the following preferences: {preferences}.\n",
    "You have the following routines: {routines}.\n",
    "{user_profile_str}\"\"\"\n",
    "    \n",
    "    user_profiles[user_id] = system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2idx = {user_id: idx for idx, user_id in enumerate(user_profiles.keys())}\n",
    "idx2user = {v: k for k, v in user2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/scratch/CRUISE/Wilson/micromamba/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/srv/scratch/CRUISE/Wilson/micromamba/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2281/2281 [06:54<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "user_profile_embeddings = model.encode(list(user_profiles.values()), batch_size=1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2281/2281 [00:30<00:00, 75.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "user2similarity = {}\n",
    "top_k = 100\n",
    "\n",
    "for user_id in tqdm(user_profiles):\n",
    "    current_user_idx = user2idx[user_id]\n",
    "    user_profile_embedding = user_profile_embeddings[current_user_idx]\n",
    "    # calculate cosine similarity between user_profile_embedding and all other user_profile_embeddings\n",
    "    similarity_scores = model.similarity(user_profile_embedding, user_profile_embeddings)[0]\n",
    "    # sort similarity scores in descending order\n",
    "    scores, indices = torch.sort(similarity_scores, descending=True)\n",
    "    for score, idx in zip(scores, indices):\n",
    "        if idx == current_user_idx:\n",
    "            continue\n",
    "        user2similarity[user_id] = user2similarity.get(user_id, [])\n",
    "        user2similarity[user_id].append((str(idx2user[idx.item()]), round(score.item(), 4)))\n",
    "        if len(user2similarity[user_id]) == top_k:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_path / \"profile_similarities.json\", \"w\") as f:\n",
    "    json.dump(user2similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
